{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from load_data import load_heart_data, load_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = load_heart_data(\"heart_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train X:  (820, 13) , Type:  <class 'numpy.ndarray'>\n",
      "Shape of Test X:  (205, 13) , Type:  <class 'numpy.ndarray'>\n",
      "Shape of Train y:  (820,) , Type:  <class 'numpy.ndarray'>\n",
      "Shape of Test y:  (205,) , Type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train X: \", train_X.shape, \", Type: \", type(train_X))\n",
    "print(\"Shape of Test X: \", test_X.shape, \", Type: \", type(test_X))\n",
    "print(\"Shape of Train y: \", train_y.shape, \", Type: \", type(train_y))\n",
    "print(\"Shape of Test y: \", test_y.shape, \", Type: \", type(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Performance\n",
    "\n",
    "Before testing out the new method explored in the project regarding the locally weighted trees, we will first test out the existing method we aim to improve upon, the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the best random forrest model, we need to tune the hyperparameters. Will do \n",
    "# so by performing a grid search \n",
    "\n",
    "grid_search_parameters = {'max_depth':[5, 10, 15, 30, 50, None], \n",
    "                          'n_estimators':[10, 25, 50, 100, 250, 500, 1000], \n",
    "                          'max_samples': [0.3, 0.5, 0.7, 0.8, 0.9, 1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
    "random_forest_classifier_GS = GridSearchCV(random_forest_classifier, grid_search_parameters, cv=10, verbose=0)\n",
    "random_forest_classifier_GS.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'max_samples': 0.9, 'n_estimators': 50}\n",
      "Best Score:  0.9902439024390244\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", random_forest_classifier_GS.best_params_)\n",
    "print(\"Best Score: \", random_forest_classifier_GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97222   0.98592       108\n",
      "           1    0.97000   1.00000   0.98477        97\n",
      "\n",
      "    accuracy                        0.98537       205\n",
      "   macro avg    0.98500   0.98611   0.98534       205\n",
      "weighted avg    0.98580   0.98537   0.98537       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters:\n",
    "random_forest_classifier = RandomForestClassifier(random_state=0, n_estimators=50, max_samples=0.9, max_depth=10)\n",
    "random_forest_classifier.fit(train_X, train_y)\n",
    "predictions = random_forest_classifier.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, predictions, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Weighted Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locallyWeightedRandomForest import LocallyWeightedRandomForest\n",
    "from sklearn.utils.estimator_checks import check_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance functions\n",
    "\n",
    "TODO move to a separate file, here for easier testing (for now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x_1:np.ndarray, x_2:np.ndarray) -> float:\n",
    "    return np.linalg.norm(x_1 - x_2)\n",
    "\n",
    "def mean_distance(point:np.ndarray, dataset:np.ndarray, distance_function:callable = lambda a,b: 1)-> float:\n",
    "    distance_sum = 0\n",
    "    for p in dataset:\n",
    "        distance_sum += distance_function(point, p)\n",
    "    return distance_sum/len(dataset)\n",
    "\n",
    "def distance_to_dataset_mean(point:np.ndarray, dataset:np.ndarray, distance_function:callable = lambda a,b: 1)-> float:\n",
    "    mean_dataset_point = np.mean(dataset, axis=0)\n",
    "    return distance_function(point, mean_dataset_point)\n",
    "\n",
    "def median_distance(point:np.ndarray, dataset:np.ndarray, distance_function:callable = lambda a,b: 1)-> float:\n",
    "    distances = []\n",
    "    for p in dataset:\n",
    "        distances.append(distance_function(point, p))\n",
    "    return statistics.median(distances)\n",
    "\n",
    "def nearest_k_distance_mean(k:int) -> callable:\n",
    "    def _smallest_k_distances_mean(point:np.ndarray, dataset:np.ndarray, distance_function:callable = lambda a,b: 1) -> float:\n",
    "        distances = np.zeros(len(dataset))\n",
    "        for i in range(len(dataset)):\n",
    "            distances[i] = distance_function(point, dataset[i])\n",
    "        smallest_k_distaces = np.sort(distances)[:k]\n",
    "        return np.mean(smallest_k_distaces, axis=0)\n",
    "\n",
    "    return _smallest_k_distances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lwrf = LocallyWeightedRandomForest(n_estimators=50, max_samples=0.9, max_depth=10)\n",
    "lwrf = LocallyWeightedRandomForest(n_estimators=50, max_samples=0.9, max_depth=10)\n",
    "#TODO: lwrf class should allow execution of predict independent of execution of fit\n",
    "#check_estimator(lwrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwrf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97222   0.98592       108\n",
      "           1    0.97000   1.00000   0.98477        97\n",
      "\n",
      "    accuracy                        0.98537       205\n",
      "   macro avg    0.98500   0.98611   0.98534       205\n",
      "weighted avg    0.98580   0.98537   0.98537       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lwrf.predict(test_X, temperature=1)\n",
    "print(classification_report(test_y, pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97222   0.98592       108\n",
      "           1    0.97000   1.00000   0.98477        97\n",
      "\n",
      "    accuracy                        0.98537       205\n",
      "   macro avg    0.98500   0.98611   0.98534       205\n",
      "weighted avg    0.98580   0.98537   0.98537       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lwrf.predict(test_X, temperature=0.15, distance_function=euclidean_distance, distance_aggregation_function=mean_distance)\n",
    "print(classification_report(test_y, pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO move to separate file \n",
    "\n",
    "def cross_validation(X, y, model, temperature, distance_function, distance_agg_func, folds=10, verbose=False):\n",
    "    k_folds = KFold(n_splits=folds)\n",
    "    validation_scores = []\n",
    "\n",
    "    for train_index, val_index in k_folds.split(X):\n",
    "        train_X, val_X = X[train_index], X[val_index]\n",
    "        train_y, val_y = y[train_index], y[val_index]\n",
    "\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "        predictions = model.predict(val_X, temperature, distance_function, distance_agg_func)\n",
    "\n",
    "        accuracy = accuracy_score(val_y, predictions)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fold Accuracy: \", accuracy)\n",
    "\n",
    "        validation_scores.append(accuracy)\n",
    "\n",
    "    return np.mean(np.array(validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing sample sizes vs performance \n",
    "\n",
    "For this graph, we will keep the number of estimators constant at 300. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the random forest, we will try various values for the portion of the population we \n",
    "# sample the data from \n",
    "sample_sizes = range(0.1, 1.01, 0.1)\n",
    "\n",
    "for size in sample_sizes:\n",
    "    lwrf = LocallyWeightedRandomForest(n_estimators=300, max_samples=size, max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9451219512195121\n",
      "Fold Accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9817073170731707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X=train_X, y=train_y, model=lwrf, temperature=1.0, distance_agg_func=mean_distance, distance_function=euclidean_distance, folds=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy:  0.975609756097561\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9634146341463414\n",
      "Fold Accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829268292682926"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X=train_X, y=train_y, model=lwrf, temperature=2.0, distance_agg_func=mean_distance, distance_function=euclidean_distance, folds=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9939024390243902\n",
      "Fold Accuracy:  0.9451219512195121\n",
      "Fold Accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9829268292682928"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X=train_X, y=train_y, model=lwrf, temperature=2.0, distance_agg_func=nearest_k_distance_mean(k=10), distance_function=euclidean_distance, folds=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9817073170731707\n",
      "Fold Accuracy:  0.9878048780487805\n",
      "Fold Accuracy:  0.9634146341463414\n",
      "Fold Accuracy:  0.9878048780487805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9817073170731707"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X=train_X, y=train_y, model=lwrf, temperature=2.0, distance_agg_func=nearest_k_distance_mean(k=1), distance_function=euclidean_distance, folds=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
