{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from load_data import load_heart_data, load_tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = load_heart_data(\"heart_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train X:  (820, 13)\n",
      "Shape of Test X:  (205, 13)\n",
      "Shape of Train y:  (820,)\n",
      "Shape of Test y:  (205,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train X: \", train_X.shape)\n",
    "print(\"Shape of Test X: \", test_X.shape)\n",
    "print(\"Shape of Train y: \", train_y.shape)\n",
    "print(\"Shape of Test y: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Performance\n",
    "\n",
    "Before testing out the new method explored in the project regarding the locally weighted trees, we will first test out the existing method we aim to improve upon, the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the best random forrest model, we need to tune the hyperparameters. Will do \n",
    "# so by performing a grid search \n",
    "\n",
    "grid_search_parameters = {'max_depth':[5, 10, 15, 30, 50, None], \n",
    "                          'n_estimators':[10, 25, 50, 100, 250, 500, 1000], \n",
    "                          'max_samples': [0.3, 0.5, 0.7, 0.8, 0.9, 1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 30, 50, None],\n",
       "                         &#x27;max_samples&#x27;: [0.3, 0.5, 0.7, 0.8, 0.9, 1],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 50, 100, 250, 500, 1000]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 15, 30, 50, None],\n",
       "                         &#x27;max_samples&#x27;: [0.3, 0.5, 0.7, 0.8, 0.9, 1],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 50, 100, 250, 500, 1000]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [5, 10, 15, 30, 50, None],\n",
       "                         'max_samples': [0.3, 0.5, 0.7, 0.8, 0.9, 1],\n",
       "                         'n_estimators': [10, 25, 50, 100, 250, 500, 1000]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
    "random_forest_classifier_GS = GridSearchCV(random_forest_classifier, grid_search_parameters, cv=10, verbose=0)\n",
    "random_forest_classifier_GS.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'max_samples': 0.9, 'n_estimators': 50}\n",
      "Best Score:  0.9902439024390244\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", random_forest_classifier_GS.best_params_)\n",
    "print(\"Best Score: \", random_forest_classifier_GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97222   0.98592       108\n",
      "           1    0.97000   1.00000   0.98477        97\n",
      "\n",
      "    accuracy                        0.98537       205\n",
      "   macro avg    0.98500   0.98611   0.98534       205\n",
      "weighted avg    0.98580   0.98537   0.98537       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters:\n",
    "random_forest_classifier = RandomForestClassifier(random_state=0, n_estimators=50, max_samples=0.9, max_depth=10)\n",
    "random_forest_classifier.fit(train_X, train_y)\n",
    "predictions = random_forest_classifier.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, predictions, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Weighted Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locallyWeightedRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lwrf = LocallyWeightedRandomForest(n_estimators=50, max_samples=0.9, max_depth=10)\n",
    "lwrf = LocallyWeightedRandomForest(n_estimators=1000, max_samples=0.5, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_euclidean_distance(point, dataset):\n",
    "    '''\n",
    "    Compute L2 distance between test point and each training point\n",
    "    \n",
    "    Input: point is a 1d numpy array\n",
    "    Output: dist is a numpy array containing the distances between the test point and each training point\n",
    "    '''\n",
    "    # Source: CSC2515 Homework 3 Starter Code. \n",
    "    \n",
    "    dataset_norm = (dataset**2).sum(axis=1).reshape(-1,1)\n",
    "\n",
    "    # Process test point shape\n",
    "    point = np.squeeze(point)\n",
    "    if point.ndim == 1:\n",
    "        point = point.reshape(1, -1)\n",
    "    assert point.shape[1] == dataset.shape[1]\n",
    "\n",
    "    # Compute squared distance\n",
    "    test_norm = (point**2).sum(axis=1).reshape(1,-1)\n",
    "    dist = dataset_norm + test_norm - 2*dataset.dot(point.transpose())\n",
    "\n",
    "    return np.mean(np.squeeze(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwrf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98039   0.92593   0.95238       108\n",
      "           1    0.92233   0.97938   0.95000        97\n",
      "\n",
      "    accuracy                        0.95122       205\n",
      "   macro avg    0.95136   0.95265   0.95119       205\n",
      "weighted avg    0.95292   0.95122   0.95125       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lwrf.predict(test_X, average_euclidean_distance, temperature=2)\n",
    "print(classification_report(test_y, pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0762ac1096e5adbf534c8200c60ae94ab630b0280f56ea79abbf3ac9b82bd3bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
