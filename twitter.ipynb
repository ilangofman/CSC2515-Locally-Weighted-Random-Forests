{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locallyWeightedRandomForest import LocallyWeightedRandomForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy\n",
    "import sklearn\n",
    "from word_preprocess import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (74682, 4)\n",
      "Testing shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('twitter_dataset/twitter_training.csv', header=None)\n",
    "train_df.columns = [\n",
    "    'tweet_id',\n",
    "    'video_game',\n",
    "    'sentiment',\n",
    "    'text'\n",
    "]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "\n",
    "test_df = pd.read_csv('twitter_dataset/twitter_validation.csv', header = None)\n",
    "test_df.columns = [\n",
    "    'tweet_id',\n",
    "    'video_game',\n",
    "    'sentiment',\n",
    "    'text'\n",
    "]\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (73996, 4)\n",
      "Testing shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[~train_df.isna().any(axis=1),:]\n",
    "test_df = test_df.loc[~test_df.isna().any(axis=1),:]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['clean_text'] = train_df.text.apply(lambda x: clean_string(x))\n",
    "test_df['clean_text'] = test_df.text.apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>video_game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>coming border kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting borderland kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting borderland NUMBER murder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   video_game sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                            clean_text  \n",
       "0         im getting borderland murder  \n",
       "1                   coming border kill  \n",
       "2           im getting borderland kill  \n",
       "3          im coming borderland murder  \n",
       "4  im getting borderland NUMBER murder  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (72505, 5)\n",
      "Testing shape: (999, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[~(train_df['clean_text'] == \"\"),:]\n",
    "test_df = test_df.loc[~(test_df['clean_text'] == \"\"),:]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text To Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "train_sbert_clean = model.encode(train_df['clean_text'].to_list())\n",
    "test_sbert_clean = model.encode(test_df['clean_text'].to_list())\n",
    "train_sbert_raw = model.encode(train_df['text'].to_list())\n",
    "test_sbert_raw = model.encode(test_df['text'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save encodings to csv\n",
    "np.savetxt('twitter_dataset/train_sbert_clean.csv', train_sbert_clean, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/test_sbert_clean.csv', test_sbert_clean, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/train_sbert_raw.csv', train_sbert_raw, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/test_sbert_raw.csv', test_sbert_raw, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in numpy data\n",
    "train_sbert_clean = np.loadtxt('twitter_dataset/train_sbert_clean.csv', delimiter=',')\n",
    "test_sbert_clean = np.loadtxt('twitter_dataset/test_sbert_clean.csv', delimiter=',')\n",
    "train_sbert_raw = np.loadtxt('twitter_dataset/train_sbert_raw.csv', delimiter=',')\n",
    "test_sbert_raw = np.loadtxt('twitter_dataset/test_sbert_raw.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# set up X and y variables\n",
    "X_train = train_sbert_raw\n",
    "X_test = test_sbert_raw\n",
    "y_train = train_df['sentiment'].values\n",
    "y_test = test_df['sentiment'].values\n",
    "\n",
    "lwrf = LocallyWeightedRandomForest(n_estimators=100, max_samples = 0.9, max_depth = 10)\n",
    "lwrf.fit(X_train, y_train)\n",
    "pred = lwrf.predict(X_test, temperature=1)\n",
    "print(classification_report(y_test, pred, digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('CSC2515')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d72f0bf83a3d946b6895dd2f7acb78ff6dbb3ccd9c0630de58d025bf03c51db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
