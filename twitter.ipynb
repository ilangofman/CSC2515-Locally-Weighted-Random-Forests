{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locallyWeightedRandomForest import LocallyWeightedRandomForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy\n",
    "import sklearn\n",
    "from word_preprocess import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (74682, 4)\n",
      "Testing shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('twitter_dataset/twitter_training.csv', header=None)\n",
    "train_df.columns = [\n",
    "    'tweet_id',\n",
    "    'video_game',\n",
    "    'sentiment',\n",
    "    'text'\n",
    "]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "\n",
    "test_df = pd.read_csv('twitter_dataset/twitter_validation.csv', header = None)\n",
    "test_df.columns = [\n",
    "    'tweet_id',\n",
    "    'video_game',\n",
    "    'sentiment',\n",
    "    'text'\n",
    "]\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (73996, 4)\n",
      "Testing shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[~train_df.isna().any(axis=1),:]\n",
    "test_df = test_df.loc[~test_df.isna().any(axis=1),:]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_index = np.unique(train_df['tweet_id'], return_index=True)[1]\n",
    "train_df = train_df.iloc[unique_train_index, :]\n",
    "print(f'Training shape: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['clean_text'] = train_df.text.apply(lambda x: clean_string(x))\n",
    "test_df['clean_text'] = test_df.text.apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>video_game</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>coming border kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting borderland kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting borderland NUMBER murder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   video_game sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                            clean_text  \n",
       "0         im getting borderland murder  \n",
       "1                   coming border kill  \n",
       "2           im getting borderland kill  \n",
       "3          im coming borderland murder  \n",
       "4  im getting borderland NUMBER murder  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (72505, 5)\n",
      "Testing shape: (999, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[~(train_df['clean_text'] == \"\"),:]\n",
    "test_df = test_df.loc[~(test_df['clean_text'] == \"\"),:]\n",
    "print(f'Training shape: {train_df.shape}')\n",
    "print(f'Testing shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text To Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "train_sbert_clean = model.encode(train_df['clean_text'].to_list())\n",
    "test_sbert_clean = model.encode(test_df['clean_text'].to_list())\n",
    "train_sbert_raw = model.encode(train_df['text'].to_list())\n",
    "test_sbert_raw = model.encode(test_df['text'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save encodings to csv\n",
    "np.savetxt('twitter_dataset/train_sbert_clean.csv', train_sbert_clean, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/test_sbert_clean.csv', test_sbert_clean, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/train_sbert_raw.csv', train_sbert_raw, delimiter = ',')\n",
    "np.savetxt('twitter_dataset/test_sbert_raw.csv', test_sbert_raw, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in numpy data\n",
    "train_sbert_clean = np.loadtxt('twitter_dataset/train_sbert_clean.csv', delimiter=',')\n",
    "test_sbert_clean = np.loadtxt('twitter_dataset/test_sbert_clean.csv', delimiter=',')\n",
    "train_sbert_raw = np.loadtxt('twitter_dataset/train_sbert_raw.csv', delimiter=',')\n",
    "test_sbert_raw = np.loadtxt('twitter_dataset/test_sbert_raw.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller = LabelEncoder()\n",
    "# set up X and y variables\n",
    "X_train = train_sbert_raw\n",
    "X_test = test_sbert_raw\n",
    "y_train = labeller.fit_transform(train_df['sentiment'].values)\n",
    "y_test = labeller.transform(test_df['sentiment'].values)\n",
    "\n",
    "grid_search_parameters = {'max_depth':[5, 10, 15, 30, 50, None], \n",
    "                          'n_estimators':[10, 25, 50, 100, 250, 500, 1000], \n",
    "                          'max_samples': [0.3, 0.5, 0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
    "random_forest_classifier_GS = GridSearchCV(random_forest_classifier, grid_search_parameters, cv=10, verbose=3)\n",
    "random_forest_classifier_GS.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", random_forest_classifier_GS.best_params_)\n",
    "print(\"Best Score: \", random_forest_classifier_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller = LabelEncoder()\n",
    "# set up X and y variables\n",
    "X_train = train_sbert_raw\n",
    "X_test = test_sbert_raw\n",
    "y_train = labeller.fit_transform(train_df['sentiment'].values)\n",
    "y_test = labeller.transform(test_df['sentiment'].values)\n",
    "\n",
    "lwrf = LocallyWeightedRandomForest(n_estimators=5, max_samples = 0.9, max_depth = 5)\n",
    "\n",
    "from importlib import reload\n",
    "import locallyWeightedRandomForest\n",
    "reload(locallyWeightedRandomForest)\n",
    "from locallyWeightedRandomForest import LocallyWeightedRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=1;, score=0.345 total time=  51.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=1;, score=0.343 total time=  52.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=1;, score=0.340 total time=  52.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=1;, score=0.319 total time=  53.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=1;, score=0.347 total time=  53.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=5;, score=0.367 total time=  53.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=5;, score=0.353 total time=  53.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=5;, score=0.351 total time=  53.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=5;, score=0.321 total time=  53.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=5, temp=5;, score=0.345 total time=  53.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=1;, score=0.343 total time= 1.8min\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=1;, score=0.353 total time= 1.8min\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=1;, score=0.345 total time= 1.8min\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=1;, score=0.333 total time= 1.8min\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=1;, score=0.342 total time= 1.8min\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=5;, score=0.355 total time= 1.8min\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=5;, score=0.354 total time= 1.8min\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=5;, score=0.351 total time= 1.8min\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=5;, score=0.336 total time=21.4min\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_samples=0.8, n_estimators=10, temp=5;, score=0.348 total time= 2.8min\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=1;, score=0.401 total time= 2.3min\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=1;, score=0.398 total time= 2.3min\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=1;, score=0.365 total time= 2.3min\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=1;, score=0.362 total time= 2.3min\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=1;, score=0.391 total time= 2.3min\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=5;, score=0.396 total time= 2.3min\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=5;, score=0.394 total time= 2.9min\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=5;, score=0.373 total time= 2.8min\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=5;, score=0.359 total time= 2.7min\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=5, temp=5;, score=0.393 total time= 2.7min\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=1;, score=0.417 total time= 5.3min\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=1;, score=0.400 total time= 5.3min\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=1;, score=0.387 total time= 5.3min\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=1;, score=0.360 total time= 5.3min\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=1;, score=0.397 total time= 5.3min\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=5;, score=0.413 total time= 5.3min\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=5;, score=0.410 total time= 5.3min\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=5;, score=0.383 total time= 5.3min\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=5;, score=0.376 total time= 5.3min\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_samples=0.8, n_estimators=10, temp=5;, score=0.394 total time= 5.4min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LocallyWeightedRandomForest(max_depth=5, max_samples=0.9,\n",
       "                                                   n_estimators=5),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_depth&#x27;: [5, 10],\n",
       "                         &#x27;max_samples&#x27;: [0.8], &#x27;n_estimators&#x27;: [5, 10],\n",
       "                         &#x27;temp&#x27;: [1, 5]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LocallyWeightedRandomForest(max_depth=5, max_samples=0.9,\n",
       "                                                   n_estimators=5),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;max_depth&#x27;: [5, 10],\n",
       "                         &#x27;max_samples&#x27;: [0.8], &#x27;n_estimators&#x27;: [5, 10],\n",
       "                         &#x27;temp&#x27;: [1, 5]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LocallyWeightedRandomForest</label><div class=\"sk-toggleable__content\"><pre>LocallyWeightedRandomForest(max_depth=5, max_samples=0.9, n_estimators=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LocallyWeightedRandomForest</label><div class=\"sk-toggleable__content\"><pre>LocallyWeightedRandomForest(max_depth=5, max_samples=0.9, n_estimators=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LocallyWeightedRandomForest(max_depth=5, max_samples=0.9,\n",
       "                                                   n_estimators=5),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [5, 10],\n",
       "                         'max_samples': [0.8], 'n_estimators': [5, 10],\n",
       "                         'temp': [1, 5]},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\" : [5,10],\n",
    "    \"criterion\" : ['gini'],\n",
    "    \"max_depth\" : [5,10],\n",
    "    \"max_samples\" : [0.8],\n",
    "    \"temp\" : [1, 5]\n",
    "}\n",
    "gcv = GridSearchCV(\n",
    "    estimator=lwrf,\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'f1_weighted',\n",
    "    verbose = 3\n",
    ")\n",
    "\n",
    "gcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3951096934453628"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e39562d0025b083e560a4f4ee443a1d3260eda45acd5bf089e927a411df2cae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
